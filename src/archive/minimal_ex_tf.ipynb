{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal Example using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation (same as in section 4, but with the np.savez(...) line of code added)\n",
    "\n",
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10, high=10, size=(observations, 1)) # 1000x1\n",
    "zs = np.random.uniform(-10, 10, (observations, 1)) # 1000x1\n",
    "\n",
    "generated_inputs = np.column_stack((xs, zs)) # 1000x2\n",
    "noise = np.random.uniform(-1, 1, (observations, 1)) # 1000x1\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise # 1000x1\n",
    "\n",
    "np.savez('minimal_ex_tf', inputs=generated_inputs, targets=generated_targets)\n",
    "# .npz is basically TF's file type, which stores arrays/tensors.\n",
    "# Common to open data like a .csv, preprocess it, then save as .npz file. Then later, build algorithm w/ .npz.\n",
    "# Note: The above keys, \"inputs\" and \"targets\" can be called anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 43.1009 \n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 5.7749\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 1.8346\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - loss: 0.7594\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.4523\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 0.3552\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - loss: 0.3296\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.3527\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 0.3251\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 0.3044\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 0.3245\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.3382\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 0.3399\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.3372\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3395\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - loss: 0.3101\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.3278\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.3382\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.3323\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.3292\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - loss: 0.3499\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.3281\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.3303\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3326\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.3259\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.3210\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3103\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3393\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3281\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - loss: 0.3195\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.3155\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3185\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.3338\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.3498\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.3213\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.3218\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.3202\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - loss: 0.3356\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.3174\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.3414\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.3266\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step - loss: 0.3441\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - loss: 0.3262\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.3307\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3409\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3389\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.3428\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3451\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 0.3338\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step - loss: 0.3238\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.3296\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3142\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.3332\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.3304\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3421\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 0.3288\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.3398\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 0.3440\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.3337\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.3176\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3213\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step - loss: 0.3278\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.3226\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 694us/step - loss: 0.3262\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.3103\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 0.3183\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.3223\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.3732\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.3510\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.3254\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 0.3554\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.3218\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3096\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.3218\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.3528\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.3231\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - loss: 0.3223\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 0.3505\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.3401\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3271\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3223\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.3241\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.3441\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 0.3405\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.3437\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.3213\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - loss: 0.3334\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - loss: 0.3114\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.3429\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 0.3264\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.3386\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.3362\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 0.3518\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3204\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - loss: 0.3361\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.3367\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - loss: 0.3393\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 0.3237\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - loss: 0.3251\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2460e303ad0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach A (simpler with default initializers and learning rate): Load the .npz file and Train the model\n",
    "\n",
    "training_data = np.load('minimal_ex_tf.npz')\n",
    "# Note: Access tensors using keys similar to a dict -> Ex: training_data['inputs'] or training_data['targets']\n",
    "\n",
    "input_size = 2 # xs and zs\n",
    "output_size = 1 # Y or generated_targets\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(output_size)\n",
    "    ]\n",
    ")\n",
    "# Sequential() function specifies how the model will be \"laid down\" (\"stacks layers\") and can also initialize weights\n",
    "# Dense(output size) takes inputs provided to the model and calculates the dot product of inputs and weights and adds bias\n",
    "# ^ (optional) also applies activation function\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "# model.compile(optimizer, loss) configures the model for training. \"sgd\" = stochastic gradient descent\n",
    "# Use MSE for L2-norm. \n",
    "# Note: Another loss for regression in \"Huber Loss,\" which is better when we have outliers, as it is less sensitive to them. Combines absolute and squared loss.\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=1)\n",
    "# model.fit(inputs, targets) fits (trains) the model\n",
    "# epochs = iterations over the full dataset\n",
    "# verbose=0 -> no output. verbose=1 -> progress bar + details. verbose=2 -> details, no progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - loss: 60.7106 \n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 1.7136\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 0.4623\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.3898\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - loss: 0.3609\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.5772\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - loss: 0.3784\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 0.3744\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3751\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 0.3692\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - loss: 0.3950\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - loss: 0.4659\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.4140\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.4366\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.4244\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - loss: 0.3792\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.3679\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - loss: 0.5462\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.4259\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601us/step - loss: 0.3760\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.3998\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.4112\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 0.4260\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 0.4585\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.4123\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3924\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.4347\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3792\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - loss: 0.3655\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - loss: 0.5125\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 0.3906\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3576\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.3768\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - loss: 0.3714\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - loss: 0.3859\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.3908\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - loss: 0.3914\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 0.4327\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.3788\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - loss: 0.4090\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - loss: 0.4825\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 0.4089\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - loss: 0.4499\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step - loss: 0.3763\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.3877\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - loss: 0.3781\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 0.4410\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.3871\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 598us/step - loss: 0.3816\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555us/step - loss: 0.3571\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.3608\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 0.3717\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 0.4121\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - loss: 0.3751\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558us/step - loss: 0.3454\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.4321\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - loss: 0.3932\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.3984\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 0.4359\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - loss: 0.3426\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 0.3964\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568us/step - loss: 0.3477\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - loss: 0.3816\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - loss: 0.3911\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - loss: 0.5728\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.4210\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - loss: 0.4161\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 585us/step - loss: 0.3640\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 0.3495\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 0.3738\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 0.3302\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.4849\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 0.3902\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.4032\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - loss: 0.3440\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538us/step - loss: 0.3790\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.4098\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.3728\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - loss: 0.3925\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 0.3987\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 580us/step - loss: 0.5677\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 0.4343\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.4503\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - loss: 0.3722\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - loss: 0.3658\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step - loss: 0.3706\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - loss: 0.3514\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - loss: 0.4663\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 0.4303\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.3553\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588us/step - loss: 0.3691\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.4313\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - loss: 0.4038\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - loss: 0.4430\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 0.4058\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.4307\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - loss: 0.4291\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.3646\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - loss: 0.4098\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - loss: 0.3946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bff0401040>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach B: Load the .npz file and Train the model, but with initializers in Dense() and custom_optomizer in compile\n",
    "# This approach is more explicit to match the weight/bias initializer and learning rate from the numpy example in section 4\n",
    "\n",
    "training_data = np.load('tf_intro.npz')\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# Below 3 lines are updated\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            output_size,\n",
    "            kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1), # kernel means weight here\n",
    "            bias_initializer=tf.random_uniform_initializer(-0.1, 0.1)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
    "\n",
    "model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0302706]\n",
      " [-2.9958396]] , [4.9941783]\n"
     ]
    }
   ],
   "source": [
    "# Extract the weights and bias\n",
    "\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "bias = model.layers[0].get_weights()[1]\n",
    "print(weights, ',', bias) # [[ 2.0561464] [-3.0132828]] , [5.0186114]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.6]\n",
      " [ 24.7]\n",
      " [ 15.9]\n",
      " [ 20.5]\n",
      " [  2.3]]\n",
      "[[-13.8]\n",
      " [ 24.2]\n",
      " [ 16.1]\n",
      " [ 20.6]\n",
      " [  1.7]]\n"
     ]
    }
   ],
   "source": [
    "# Make \"predictions\" (using training data and compare to targets)\n",
    "\n",
    "predictions = model.predict_on_batch(training_data['inputs'])\n",
    "# model.predict_on_batch(data) calculates the outputs given inputs\n",
    "\n",
    "# Compare the first 5 observations\n",
    "print(predictions.round(1)[:5])\n",
    "print(training_data['targets'].round(1)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "\n",
    "plt.plot(np.squeeze(predictions), np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()\n",
    "\n",
    "# Note to self: Not sure why np.squeeze is needed since predictions and targets are both 1000x1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
